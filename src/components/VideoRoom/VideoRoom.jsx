// üìÑ VideoRoom.jsx
import { useEffect, useRef, useState } from "react";
import { useNavigate, useParams } from "react-router-dom";
import { checkCallAccess } from "../../api/callApi";
import { socket } from "../../api/socket";
import { toast } from "react-toastify";
import styles from "./VideoRoom.module.css";
import cameraIcon from "../../assets/camera.svg";
import cameraOffIcon from "../../assets/camera-off.svg";
import microphoneIcon from "../../assets/microphone.svg";
import microphoneOffIcon from "../../assets/microphone-off.svg";
import exitIcon from "../../assets/exit.svg";

const servers = {
  iceServers: [
    { urls: "stun:stun.l.google.com:19302" },
    { urls: "stun:stun1.l.google.com:19302" },
  ],
};

const createSilentAudioTrack = () => {
  const ctx = new AudioContext();
  const oscillator = ctx.createOscillator();
  const dst = oscillator.connect(ctx.createMediaStreamDestination());
  oscillator.start();
  const track = dst.stream.getAudioTracks()[0];
  return Object.assign(track, { enabled: false });
};

const createBlackVideoTrack = ({ width = 640, height = 480 } = {}) => {
  const canvas = Object.assign(document.createElement("canvas"), {
    width,
    height,
  });
  canvas.getContext("2d").fillRect(0, 0, width, height);
  const stream = canvas.captureStream();
  const track = stream.getVideoTracks()[0];
  return Object.assign(track, { enabled: false });
};

const VideoRoom = () => {
  const { callId } = useParams();
  const navigate = useNavigate();
  const [currentRole, setCurrentRole] = useState(null);
  const [cameraEnabled, setCameraEnabled] = useState(true);
  const [micEnabled, setMicEnabled] = useState(true);
  const [localStream, setLocalStream] = useState(null);
  const [remoteStream, setRemoteStream] = useState(null);
  const [isRemoteConnected, setIsRemoteConnected] = useState(false);
  const [focused, setFocused] = useState("remote");

  const pcRef = useRef(null);
  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const remoteAudioRef = useRef(null);

  useEffect(() => {
    const checkAccess = async () => {
      try {
        const res = await checkCallAccess(callId);
        setCurrentRole(res.role);
        console.log("‚úÖ –î–æ—Å—Ç—É–ø –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–æ. –†–æ–ª—å:", res.role);
      } catch (err) {
        alert("–î–æ—Å—Ç—É–ø –¥–æ –∫—ñ–º–Ω–∞—Ç–∏ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ.");
        navigate("/");
      }
    };
    checkAccess();
  }, [callId, navigate]);

  useEffect(() => {
    if (remoteVideoRef.current && remoteStream) {
      remoteVideoRef.current.srcObject = remoteStream;
      remoteVideoRef.current.muted = true; // –¥–ª—è autoplay
      remoteVideoRef.current.volume = 0;

      setTimeout(() => {
        remoteVideoRef.current
          .play()
          .then(() => console.log("‚ñ∂Ô∏è Remote video playing"))
          .catch((e) =>
            console.warn("‚ö†Ô∏è Remote video play failed in useEffect:", e)
          );
      }, 0);
    }
  }, [remoteStream]);

  useEffect(() => {
    if (remoteAudioRef.current) {
      remoteAudioRef.current.muted = false;
      remoteAudioRef.current.volume = 1;
    }
  }, [remoteStream]);

  useEffect(() => {
    if (!currentRole) return;

    const pc = new RTCPeerConnection(servers);
    pcRef.current = pc;
    const stream = new MediaStream();
    setRemoteStream(stream);

    pc.addTransceiver("audio", { direction: "sendrecv" });
    pc.addTransceiver("video", { direction: "sendrecv" });
    pc.addTransceiver("audio", { direction: "recvonly" });
    pc.addTransceiver("video", { direction: "recvonly" });

    const start = async () => {
      const devices = await navigator.mediaDevices.enumerateDevices();
      const mics = devices.filter((d) => d.kind === "audioinput");
      const cams = devices.filter((d) => d.kind === "videoinput");

      console.log(
        "üéß –ú—ñ–∫—Ä–æ—Ñ–æ–Ω–∏:",
        mics.map((d) => d.label || "Unnamed")
      );
      console.log(
        "üì∏ –ö–∞–º–µ—Ä–∏:",
        cams.map((d) => d.label || "Unnamed")
      );

      let audioTrack, videoTrack;

      try {
        const audioStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });
        audioTrack = audioStream.getAudioTracks()[0];
        console.log(
          "üéôÔ∏è –û—Ç—Ä–∏–º–∞–Ω–æ –∞—É–¥—ñ–æ:",
          audioTrack.label,
          "| enabled:",
          audioTrack.enabled
        );
      } catch (e) {
        console.warn("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∞—É–¥—ñ–æ:", e);
        audioTrack = createSilentAudioTrack();
        console.log("üé≠ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ñ–µ–π–∫–æ–≤–∏–π –∞—É–¥—ñ–æ —Ç—Ä–µ–∫");
      }

      try {
        const videoStream = await navigator.mediaDevices.getUserMedia({
          video: true,
        });
        videoTrack = videoStream.getVideoTracks()[0];
        console.log(
          "üì∑ –û—Ç—Ä–∏–º–∞–Ω–æ –≤—ñ–¥–µ–æ:",
          videoTrack.label,
          "| enabled:",
          videoTrack.enabled
        );
      } catch (e) {
        console.warn("‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—ñ–¥–µ–æ:", e);
        videoTrack = createBlackVideoTrack();
        console.log("üé≠ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ñ–µ–π–∫–æ–≤–∏–π –≤—ñ–¥–µ–æ —Ç—Ä–µ–∫");
      }

      const local = new MediaStream([audioTrack, videoTrack].filter(Boolean));
      setLocalStream(local);

      local.getTracks().forEach((track) => {
        pc.addTrack(track, local);
        console.log(
          `üé• –î–æ–¥–∞—î–º–æ —Ç—Ä–µ–∫: ${track.kind} | enabled: ${track.enabled}`
        );
      });

      if (localVideoRef.current) {
        localVideoRef.current.srcObject = local;
      }

      socket.emit("join-room", { callId });
      console.log(`üö™ –í—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ join-room ‚Üí callId: ${callId}`);
    };

    pc.onicecandidate = (event) => {
      if (event.candidate) {
        socket.emit("ice-candidate", { callId, candidate: event.candidate });
      }
    };

    pc.ontrack = (event) => {
      console.log(
        "üì• –û—Ç—Ä–∏–º–∞–Ω–æ remote track:",
        event.track.kind,
        "| enabled:",
        event.track.enabled
      );

      const incomingStream = event.streams[0];

      // –ü—Ä–∏–∑–Ω–∞—á–∞—î–º–æ stream –Ω–∞–ø—Ä—è–º—É —ñ –æ–Ω–æ–≤–ª—é—î–º–æ —Å—Ç–∞–Ω
      if (remoteVideoRef.current) {
        remoteVideoRef.current.srcObject = incomingStream;
        remoteVideoRef.current.muted = true; // autoplay –±–µ–∑ interaction
        remoteVideoRef.current.volume = 0;

        setTimeout(() => {
          remoteVideoRef.current
            .play()
            .then(() => console.log("‚ñ∂Ô∏è Remote video playing"))
            .catch((e) => console.warn("‚ö†Ô∏è Video play failed:", e));
        }, 0);
      }

      if (remoteAudioRef.current) {
        remoteAudioRef.current.srcObject = incomingStream;
        remoteAudioRef.current.muted = false;
        remoteAudioRef.current.volume = 1;

        setTimeout(() => {
          remoteAudioRef.current
            .play()
            .then(() => console.log("üéß Remote audio playing"))
            .catch((e) => console.warn("‚ö†Ô∏è Audio play failed:", e));
        }, 0);
      }

      console.log("üéß –ü–æ—Ç—ñ–∫ —É audio:", incomingStream?.getAudioTracks());

      setRemoteStream(incomingStream);
      setIsRemoteConnected(true);
    };

    socket.on("user-joined", async () => {
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      console.log("üì® –í—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ offer:", offer.sdp);
      socket.emit("offer", { callId, offer });
    });

    socket.on("user-left", () => {
      toast.info("–û–ø–æ–Ω–µ–Ω—Ç –∑–∞–ª–∏—à–∏–≤ –∫—ñ–º–Ω–∞—Ç—É");
      remoteStream
        ?.getTracks()
        .forEach((track) => remoteStream.removeTrack(track));
      if (remoteVideoRef.current) remoteVideoRef.current.srcObject = null;
      if (remoteAudioRef.current) remoteAudioRef.current.srcObject = null;
      setIsRemoteConnected(false);
    });

    socket.on("offer", async ({ offer }) => {
      console.log("üì© –û—Ç—Ä–∏–º–∞–Ω–æ offer SDP:", offer.sdp);
      await pc.setRemoteDescription(new RTCSessionDescription(offer));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      socket.emit("answer", { callId, answer });
    });

    socket.on("answer", async ({ answer }) => {
      await pc.setRemoteDescription(new RTCSessionDescription(answer));
    });

    socket.on("ice-candidate", async ({ candidate }) => {
      try {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
      } catch (err) {
        console.error("‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –¥–æ–¥–∞–≤–∞–Ω–Ω—è ICE:", err);
      }
    });

    start();

    return () => {
      localStream?.getTracks().forEach((track) => track.stop());
      pc.close();
      socket.emit("leave-room", { callId });
      socket.off("user-joined");
      socket.off("user-left");
      socket.off("offer");
      socket.off("answer");
      socket.off("ice-candidate");
    };
  }, [currentRole, callId]);

  const leaveRoom = () => navigate("/");

  const toggleMic = () => {
    const track = localStream?.getAudioTracks()[0];
    if (track) {
      track.enabled = !track.enabled;
      setMicEnabled(track.enabled);
    }
  };

  const toggleCamera = () => {
    const track = localStream?.getVideoTracks()[0];
    if (track) {
      track.enabled = !track.enabled;
      setCameraEnabled(track.enabled);
    }
  };

  return (
    <div className={styles.container}>
      <h2>–í—ñ–¥–µ–æ–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü—ñ—è</h2>
      <p>
        –í–∏ –ø—Ä–∏—î–¥–Ω–∞–ª–∏—Å—å –¥–æ –∫—ñ–º–Ω–∞—Ç–∏: <strong>{callId}</strong>
      </p>

      <div className={styles.videoContainer}>
        <div
          className={
            focused === "local"
              ? styles.focusedVideoWrapper
              : focused === "remote"
              ? styles.miniVideoWrapper
              : styles.equalVideo
          }
          onClick={() => setFocused(focused === "local" ? null : "local")}
        >
          <p className={styles.videoLabel}>–í–∏ ({currentRole})</p>
          <video
            ref={localVideoRef}
            autoPlay
            muted
            playsInline
            className={styles.video}
          />
        </div>

        <div
          className={
            focused === "remote"
              ? styles.focusedVideoWrapper
              : focused === "local"
              ? styles.miniVideoWrapper
              : styles.equalVideo
          }
          onClick={() => setFocused(focused === "remote" ? null : "remote")}
        >
          <p className={styles.videoLabel}>–û–ø–æ–Ω–µ–Ω—Ç</p>
          {isRemoteConnected ? (
            <video
              ref={remoteVideoRef}
              autoPlay
              playsInline
              muted
              className={styles.video}
            />
          ) : (
            <div className={styles.placeholder}>
              –û—á—ñ–∫—É—î–º–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –æ–ø–æ–Ω–µ–Ω—Ç–∞...
            </div>
          )}
        </div>
      </div>

      <audio ref={remoteAudioRef} autoPlay />

      <div className={styles.controls}>
        <button onClick={toggleMic}>
          <img
            src={micEnabled ? microphoneIcon : microphoneOffIcon}
            alt={micEnabled ? "–ú—ñ–∫—Ä–æ—Ñ–æ–Ω —É–≤—ñ–º–∫–Ω–µ–Ω–æ" : "–ú—ñ–∫—Ä–æ—Ñ–æ–Ω –≤–∏–º–∫–Ω–µ–Ω–æ"}
            className={styles.icon}
          />
        </button>
        <button onClick={toggleCamera}>
          <img
            src={cameraEnabled ? cameraIcon : cameraOffIcon}
            alt={cameraEnabled ? "–ö–∞–º–µ—Ä–∞ —É–≤—ñ–º–∫–Ω–µ–Ω–∞" : "–ö–∞–º–µ—Ä–∞ –≤–∏–º–∫–Ω–µ–Ω–∞"}
            className={styles.icon}
          />
        </button>
        <button onClick={leaveRoom} className={styles.leaveButton}>
          <img className={styles.icon} src={exitIcon} alt="–í–∏–π—Ç–∏ –∑ –∫—ñ–º–Ω–∞—Ç–∏" />
        </button>
      </div>
    </div>
  );
};

export default VideoRoom;
